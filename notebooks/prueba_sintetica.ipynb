{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# ---------- 1. Grafo bipartito y labels ----------\n",
    "def make_bipartite_graph(n_per_class=50, p_edge=0.1, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Creamos un grafo bipartito A-B\n",
    "    A_nodes = list(range(n_per_class))\n",
    "    B_nodes = list(range(n_per_class, 2 * n_per_class))\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(A_nodes, bipartite=0, label=0) \n",
    "    G.add_nodes_from(B_nodes, bipartite=1, label=1)\n",
    "    \n",
    "    # Añadimos aristas aleatorias entre A y B\n",
    "    for a in A_nodes:\n",
    "        for b in B_nodes:\n",
    "            if rng.rand() < p_edge:\n",
    "                G.add_edge(a, b)\n",
    "    \n",
    "    # Nos aseguramos de que el grafo sea conectado\n",
    "    if not nx.is_connected(G):\n",
    "        # Conectar componentes a lo bruto\n",
    "        comps = list(nx.connected_components(G))\n",
    "        for i in range(len(comps) - 1):\n",
    "            u = next(iter(comps[i]))\n",
    "            v = next(iter(comps[i+1]))\n",
    "            G.add_edge(u, v)\n",
    "    \n",
    "    labels = np.array([G.nodes[i]['label'] for i in G.nodes()])\n",
    "    \n",
    "    # Lista de aristas como pares (u, v)\n",
    "    edges = np.array(list(G.edges()), dtype=np.int64)\n",
    "    return G, edges, labels\n",
    "\n",
    "# ---------- 2. Features Gaussianos solapados ----------\n",
    "def make_gaussian_features(labels, mu=1.0, sigma=1.0, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = len(labels)\n",
    "    fdim = 2  # 2D para poder visualizar\n",
    "    X = np.zeros((n, fdim), dtype=np.float32)\n",
    "    \n",
    "    # Clase 0: N((-mu, 0), sigma^2 I)\n",
    "    # Clase 1: N((+mu, 0), sigma^2 I)\n",
    "    for i, y in enumerate(labels):\n",
    "        mean = np.array([-mu, 0.0]) if y == 0 else np.array([+mu, 0.0])\n",
    "        X[i] = rng.normal(loc=mean, scale=sigma, size=(fdim,))\n",
    "    return X.astype(np.float32)\n",
    "\n",
    "# Ejemplo de uso:\n",
    "G, edges, labels = make_bipartite_graph(n_per_class=100, p_edge=0.05, seed=0)\n",
    "X0 = make_gaussian_features(labels, mu=1.0, sigma=1.5, seed=0)\n",
    "\n",
    "X0 = torch.from_numpy(X0)          # [n, f]\n",
    "y  = torch.from_numpy(labels)      # [n]\n",
    "edges_torch = torch.from_numpy(edges)  # [m, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00900f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sheaf_laplacian_scalar(n_nodes, edges, F_ve, F_ue):\n",
    "    \"\"\"\n",
    "    n_nodes: número de nodos\n",
    "    edges: [m, 2] tensor con (v, u)\n",
    "    F_ve, F_ue: [m] tensores con los mapas F_{v->e}, F_{u->e}\n",
    "    \n",
    "    Devuelve ∆_F (nd x nd) con d=1, así que es [n, n]\n",
    "    \"\"\"\n",
    "    m = edges.shape[0]\n",
    "    L = torch.zeros((n_nodes, n_nodes), dtype=torch.float32)\n",
    "    \n",
    "    # Para cada arista e = (v, u):\n",
    "    for e_idx in range(m):\n",
    "        v = edges[e_idx, 0].item()\n",
    "        u = edges[e_idx, 1].item()\n",
    "        fv = F_ve[e_idx]\n",
    "        fu = F_ue[e_idx]\n",
    "        \n",
    "        # Según Definition 2 del paper:\n",
    "        # L_F(x)_v = sum_{v,u~e} F_v^T(F_v x_v - F_u x_u)\n",
    "        # Lo que induce:\n",
    "        # L[v, v] += fv^2\n",
    "        # L[v, u] -= fv * fu\n",
    "        # L[u, u] += fu^2\n",
    "        # L[u, v] -= fu * fv\n",
    "        L[v, v] += fv * fv\n",
    "        L[u, u] += fu * fu\n",
    "        L[v, u] -= fv * fu\n",
    "        L[u, v] -= fu * fv\n",
    "    \n",
    "    # Normalización por D^{-1/2} (como en el paper)\n",
    "    d = torch.diag(L)\n",
    "    # Evitar división por cero\n",
    "    d_clamped = torch.clamp(d, min=1e-6)\n",
    "    D_inv_sqrt = torch.diag(1.0 / torch.sqrt(d_clamped))\n",
    "    Delta = D_inv_sqrt @ L @ D_inv_sqrt\n",
    "    return Delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c0434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhiGeneral(nn.Module):\n",
    "    \"\"\"\n",
    "    Φ general: produce F_{v->e} y F_{u->e} distintos (modelo no simétrico).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.mlp_v = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.mlp_u = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_v, x_u):\n",
    "        \"\"\"\n",
    "        x_v, x_u: [m, f]\n",
    "        devuelve: F_ve, F_ue: [m]\n",
    "        \"\"\"\n",
    "        inp = torch.cat([x_v, x_u], dim=-1)  # [m, 2f]\n",
    "        F_ve = self.mlp_v(inp).squeeze(-1)\n",
    "        F_ue = self.mlp_u(inp).squeeze(-1)\n",
    "        \n",
    "        # Para evitar mapas degenerados, puedes forzar que no sean ~0\n",
    "        return F_ve, F_ue\n",
    "\n",
    "\n",
    "class PhiSymmetric(nn.Module):\n",
    "    \"\"\"\n",
    "    Φ simétrica: F_{v->e} = F_{u->e} (modelo tipo weighted graph Laplacian).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_v, x_u):\n",
    "        inp = torch.cat([x_v, x_u], dim=-1)  # [m, 2f]\n",
    "        F_e = self.mlp(inp).squeeze(-1)\n",
    "        return F_e, F_e  # F_v = F_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07dbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafDiffusionModel(nn.Module):\n",
    "    def __init__(self, in_features, hidden_phi=32, symmetric=False, T=20, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        in_dim_phi = 2 * in_features  # [x_v || x_u]\n",
    "        if symmetric:\n",
    "            self.phi = PhiSymmetric(in_dim_phi, hidden_dim=hidden_phi)\n",
    "        else:\n",
    "            self.phi = PhiGeneral(in_dim_phi, hidden_dim=hidden_phi)\n",
    "        \n",
    "        # Clasificador lineal sobre X^T\n",
    "        self.classifier = nn.Linear(in_features, n_classes)\n",
    "    \n",
    "    def forward(self, X0, edges):\n",
    "        \"\"\"\n",
    "        X0: [n, f]\n",
    "        edges: [m, 2]\n",
    "        \"\"\"\n",
    "        n_nodes = X0.shape[0]\n",
    "        X = X0\n",
    "        \n",
    "        # Construimos F a partir de X0 (como en el paper: se aprende a t=0)\n",
    "        v_idx = edges[:, 0]\n",
    "        u_idx = edges[:, 1]\n",
    "        x_v = X0[v_idx]\n",
    "        x_u = X0[u_idx]\n",
    "        F_ve, F_ue = self.phi(x_v, x_u)  # [m]\n",
    "        \n",
    "        # Laplaciano de sheaf ∆_F (scalar, d=1)\n",
    "        Delta = build_sheaf_laplacian_scalar(n_nodes, edges, F_ve, F_ue)  # [n, n]\n",
    "        \n",
    "        # Difusión \"vanilla\": X^{t+1} = X^t - ∆_F X^t\n",
    "        for _ in range(self.T):\n",
    "            X = X - Delta @ X  # [n, f]\n",
    "        \n",
    "        # Clasificador lineal\n",
    "        logits = self.classifier(X)  # [n, n_classes]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee787c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Modelo simétrico (weighted Laplacian) ===\n",
      "Epoch 50 | loss=0.4862 | train_acc=0.781 | test_acc=0.750\n",
      "Epoch 100 | loss=0.3327 | train_acc=0.994 | test_acc=0.925\n",
      "Epoch 150 | loss=0.2229 | train_acc=1.000 | test_acc=0.975\n",
      "Epoch 200 | loss=0.1499 | train_acc=1.000 | test_acc=1.000\n",
      "\n",
      "=== Modelo general de sheaf (no simétrico) ===\n",
      "Epoch 50 | loss=0.3186 | train_acc=1.000 | test_acc=1.000\n",
      "Epoch 100 | loss=0.1671 | train_acc=1.000 | test_acc=1.000\n",
      "Epoch 150 | loss=0.1047 | train_acc=1.000 | test_acc=1.000\n",
      "Epoch 200 | loss=0.0720 | train_acc=1.000 | test_acc=1.000\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "n_per_class = 100\n",
    "G, edges, labels = make_bipartite_graph(n_per_class=n_per_class, p_edge=0.05, seed=0)\n",
    "X0 = make_gaussian_features(labels, mu=1.0, sigma=1.5, seed=0)\n",
    "\n",
    "X0 = torch.from_numpy(X0)\n",
    "y  = torch.from_numpy(labels)\n",
    "edges_torch = torch.from_numpy(edges)\n",
    "\n",
    "# Split train/test\n",
    "n = X0.shape[0]\n",
    "perm = torch.randperm(n)\n",
    "train_size = int(0.8 * n)\n",
    "train_idx = perm[:train_size]\n",
    "test_idx  = perm[train_size:]\n",
    "\n",
    "def train_model(symmetric=False):\n",
    "    model = SheafDiffusionModel(\n",
    "        in_features=X0.shape[1],\n",
    "        hidden_phi=32,\n",
    "        symmetric=symmetric,\n",
    "        T=20,\n",
    "        n_classes=2\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(X0, edges_torch)\n",
    "        loss = F.cross_entropy(logits[train_idx], y[train_idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                train_acc = (pred[train_idx] == y[train_idx]).float().mean().item()\n",
    "                test_acc  = (pred[test_idx] == y[test_idx]).float().mean().item()\n",
    "            print(f\"Epoch {epoch+1} | loss={loss.item():.4f} | train_acc={train_acc:.3f} | test_acc={test_acc:.3f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"=== Modelo simétrico (weighted Laplacian) ===\")\n",
    "sym_model = train_model(symmetric=True)\n",
    "\n",
    "print(\"\\n=== Modelo general de sheaf (no simétrico) ===\")\n",
    "gen_model = train_model(symmetric=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheaf-nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
